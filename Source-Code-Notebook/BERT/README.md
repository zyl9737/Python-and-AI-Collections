# Bidirectional Encoder Representation from Transformer（BERT）

模型部分源码阅读笔记....（工程量真的有点大，暂时只啃了模型处理的部分，待补）

blog整理：https://blog.csdn.net/qq_39388410/article/details/102136315

#

原paper：https://arxiv.org/abs/1810.04805

原code：https://github.com/google-research/bert

#

pytorch版本代码：https://github.com/huggingface/transformers
